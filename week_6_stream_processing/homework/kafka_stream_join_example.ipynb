{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Create Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.\n",
      "Created topic demo_1.\n"
     ]
    }
   ],
   "source": [
    "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --create --topic demo_1 --bootstrap-server localhost:9092 --partitions 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: demo_1\tPartitionCount: 2\tReplicationFactor: 1\tConfigs: \n",
      "\tTopic: demo_1\tPartition: 0\tLeader: 1\tReplicas: 1\tIsr: 1\n",
      "\tTopic: demo_1\tPartition: 1\tLeader: 1\tReplicas: 1\tIsr: 1\n"
     ]
    }
   ],
   "source": [
    "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic demo_1 --describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2nd Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.\n",
      "Created topic demo_2.\n"
     ]
    }
   ],
   "source": [
    "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --create --topic demo_2 --bootstrap-server localhost:9092 --partitions 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: demo_2\tPartitionCount: 2\tReplicationFactor: 1\tConfigs: \n",
      "\tTopic: demo_2\tPartition: 0\tLeader: 1\tReplicas: 1\tIsr: 1\n",
      "\tTopic: demo_2\tPartition: 1\tLeader: 1\tReplicas: 1\tIsr: 1\n"
     ]
    }
   ],
   "source": [
    "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic demo_2 --describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send message into first topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"1,1,alice\" | ./kafka_2.13-3.1.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic demo_1 --property \"parse.key=true\" --property \"key.separator=,\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"2,bob\" | ./kafka_2.13-3.1.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic demo_1 --property \"parse.key=true\" --property \"key.separator=,\"\n",
    "!echo \"3,charlie\" | ./kafka_2.13-3.1.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic demo_1 --property \"parse.key=true\" --property \"key.separator=,\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bob\n",
      "alice\n",
      "charlie\n",
      "^C\n",
      "Processed a total of 3 messages\n"
     ]
    }
   ],
   "source": [
    "!./kafka_2.13-3.1.0/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic demo_1 --from-beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send message into 2nd topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"1,alice information updated\" | ./kafka_2.13-3.1.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic demo_2 --property \"parse.key=true\" --property \"key.separator=,\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice information updated\n",
      "^C\n",
      "Processed a total of 1 messages\n"
     ]
    }
   ],
   "source": [
    "!./kafka_2.13-3.1.0/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic demo_2 --from-beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Join\n",
    "\n",
    "Using module ksql to achieve a SQL interface over Kafka Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ksql\n",
      "  Downloading ksql-0.10.2.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/desenfirman/miniconda3/lib/python3.8/site-packages (from ksql) (2.27.1)\n",
      "Requirement already satisfied: six in /home/desenfirman/miniconda3/lib/python3.8/site-packages (from ksql) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in /home/desenfirman/miniconda3/lib/python3.8/site-packages (from ksql) (1.26.8)\n",
      "Collecting hyper\n",
      "  Downloading hyper-0.7.0-py2.py3-none-any.whl (269 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting hyperframe<4.0,>=3.2\n",
      "  Downloading hyperframe-3.2.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting h2<3.0,>=2.4\n",
      "  Downloading h2-2.6.2-py2.py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/desenfirman/miniconda3/lib/python3.8/site-packages (from requests->ksql) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/desenfirman/miniconda3/lib/python3.8/site-packages (from requests->ksql) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/desenfirman/miniconda3/lib/python3.8/site-packages (from requests->ksql) (2021.10.8)\n",
      "Collecting hpack<4,>=2.2\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: ksql\n",
      "  Building wheel for ksql (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ksql: filename=ksql-0.10.2-py3-none-any.whl size=12800 sha256=53a269d4b1055424ff31dbc90cf7eae959f1433eb34c13cd12e971132d4ea4c2\n",
      "  Stored in directory: /home/desenfirman/.cache/pip/wheels/0f/40/c1/9fbdca865566449b00a3a6e0427a6cf08ce5a359dea6c684ff\n",
      "Successfully built ksql\n",
      "Installing collected packages: hyperframe, hpack, h2, hyper, ksql\n",
      "Successfully installed h2-2.6.2 hpack-3.0.0 hyper-0.7.0 hyperframe-3.2.0 ksql-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ksql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the KSQL client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:8088\n",
      "DEBUG:urllib3.connectionpool:http://localhost:8088 \"GET /info HTTP/1.1\" 200 None\n",
      "DEBUG:root:KSQL generated: show topics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'@type': 'kafka_topics',\n",
       "  'statementText': 'show topics;',\n",
       "  'topics': [{'name': '_confluent-command', 'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-actual-group-consumption-rekey',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-aggregate-topic-partition-store-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-AlertHistoryStore-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-cluster-rekey',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-expected-group-consumption-rekey',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-group-aggregate-store-ONE_MINUTE-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-group-aggregate-store-THREE_HOURS-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-Group-ONE_MINUTE-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-group-stream-extension-rekey',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-Group-THREE_HOURS-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-KSTREAM-OUTEROTHER-0000000105-store-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-KSTREAM-OUTERTHIS-0000000104-store-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-metrics-trigger-measurement-rekey',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MetricsAggregateStore-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MetricsAggregateStore-repartition',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-monitoring-aggregate-rekey-store-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-monitoring-message-rekey-store',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-monitoring-trigger-event-rekey',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringStream-ONE_MINUTE-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringStream-ONE_MINUTE-repartition',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringStream-THREE_HOURS-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringStream-THREE_HOURS-repartition',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringTriggerStore-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-MonitoringVerifierStore-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-TriggerActionsStore-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-controlcenter-5-4-0-1-TriggerEventsStore-changelog',\n",
       "    'replicaInfo': [1]},\n",
       "   {'name': '_confluent-license', 'replicaInfo': [1]},\n",
       "   {'name': '_confluent-metrics',\n",
       "    'replicaInfo': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       "   {'name': '_confluent-monitoring', 'replicaInfo': [1]},\n",
       "   {'name': '_schemas', 'replicaInfo': [1]},\n",
       "   {'name': 'default_ksql_processing_log', 'replicaInfo': [1]},\n",
       "   {'name': 'demo_1', 'replicaInfo': [1, 1]},\n",
       "   {'name': 'demo_2', 'replicaInfo': [1, 1]}],\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from ksql import KSQLAPI\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "client = KSQLAPI('http://localhost:8088')\n",
    "\n",
    "client.ksql('show topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:KSQL generated: show streams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'@type': 'streams',\n",
       "  'statementText': 'show streams;',\n",
       "  'streams': [{'type': 'STREAM',\n",
       "    'name': 'KSQL_PROCESSING_LOG',\n",
       "    'topic': 'default_ksql_processing_log',\n",
       "    'format': 'JSON'}],\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql('show streams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:KSQL generated: show tables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'@type': 'tables',\n",
       "  'statementText': 'show tables;',\n",
       "  'tables': [],\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql('show tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that I learn here. Streams are different with topics. Stream use source from topic. So, I need to create a stream using base topics that I created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:KSQL generated: \n",
      "    CREATE STREAM demo_1_stream (\n",
      "        ROWKEY STRING KEY,\n",
      "        name STRING\n",
      "    ) WITH (\n",
      "        KAFKA_TOPIC = 'demo_1',\n",
      "        VALUE_FORMAT = 'DELIMITED'\n",
      "    )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'@type': 'currentStatus',\n",
       "  'statementText': \"CREATE STREAM demo_1_stream (\\n        ROWKEY STRING KEY,\\n        name STRING\\n    ) WITH (\\n        KAFKA_TOPIC = 'demo_1',\\n        VALUE_FORMAT = 'DELIMITED'\\n    )\\n;\",\n",
       "  'commandId': 'stream/`DEMO_1_STREAM`/create',\n",
       "  'commandStatus': {'status': 'SUCCESS', 'message': 'Stream created'},\n",
       "  'commandSequenceNumber': 3,\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql(\"\"\"\n",
    "    CREATE STREAM demo_1_stream (\n",
    "        ROWKEY STRING KEY,\n",
    "        name STRING\n",
    "    ) WITH (\n",
    "        KAFKA_TOPIC = 'demo_1',\n",
    "        VALUE_FORMAT = 'DELIMITED'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:KSQL generated: \n",
      "    CREATE STREAM demo_2_stream (\n",
      "        ROWKEY STRING KEY,\n",
      "        name STRING\n",
      "    ) WITH (\n",
      "        KAFKA_TOPIC = 'demo_2',\n",
      "        VALUE_FORMAT = 'DELIMITED'\n",
      "    )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'@type': 'currentStatus',\n",
       "  'statementText': \"CREATE STREAM demo_2_stream (\\n        ROWKEY STRING KEY,\\n        name STRING\\n    ) WITH (\\n        KAFKA_TOPIC = 'demo_2',\\n        VALUE_FORMAT = 'DELIMITED'\\n    )\\n;\",\n",
       "  'commandId': 'stream/`DEMO_2_STREAM`/create',\n",
       "  'commandStatus': {'status': 'SUCCESS', 'message': 'Stream created'},\n",
       "  'commandSequenceNumber': 6,\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql(\"\"\"\n",
    "    CREATE STREAM demo_2_stream (\n",
    "        ROWKEY STRING KEY,\n",
    "        name STRING\n",
    "    ) WITH (\n",
    "        KAFKA_TOPIC = 'demo_2',\n",
    "        VALUE_FORMAT = 'DELIMITED'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test push query\n",
    "https://docs.conduktor.io/features/ksqldb/how-to-query-with-ksqldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:KSQL generated: \n",
      "    SELECT *\n",
      "    FROM demo_1_stream\n",
      "    EMIT CHANGES\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"header\":{\"queryId\":\"none\",\"schema\":\"`ROWTIME` BIGINT, `ROWKEY` STRING, `NAME` STRING\"}}\n",
      "\n",
      "{\"row\":{\"columns\":[1646153014996,\"1\",\"alice\"]}}\n",
      "\n",
      "{\"row\":{\"columns\":[1646153050443,\"3\",\"charlie\"]}}\n",
      "\n",
      "{\"row\":{\"columns\":[1646153047087,\"2\",\"bob\"]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = client.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM demo_1_stream\n",
    "    EMIT CHANGES\n",
    "\"\"\", stream_properties={\"ksql.streams.auto.offset.reset\": \"earliest\"})\n",
    "max_row = 3\n",
    "i = 0\n",
    "for item in q:\n",
    "    if i > max_row:\n",
    "        break \n",
    "    print(item)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Join\n",
    "\n",
    "Join scenario: To get an updated name information from topic demo_2 within 1 hours. demo_1 act as source table and demo_2 act as incoming changes. Here I show the difference of changed name between two topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:KSQL generated: \n",
      "    SELECT \n",
      "        A.ROWKEY,\n",
      "        A.name AS demo_1_name,\n",
      "        B.name AS demo_2_name\n",
      "    FROM demo_1_stream A\n",
      "        LEFT JOIN demo_2_stream B WITHIN 1 HOURS ON A.ROWKEY = B.ROWKEY\n",
      "    EMIT CHANGES\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"header\":{\"queryId\":\"none\",\"schema\":\"`A_ROWKEY` STRING, `DEMO_1_NAME` STRING, `DEMO_2_NAME` STRING\"}}\n",
      "\n",
      "{\"row\":{\"columns\":[\"2\",\"bob\",null]}}\n",
      "\n",
      "{\"row\":{\"columns\":[\"1\",\"alice\",null]}}\n",
      "\n",
      "{\"row\":{\"columns\":[\"3\",\"charlie\",null]}}\n",
      "\n",
      "{\"row\":{\"columns\":[\"1\",\"alice\",\"alice information updated\"]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = client.query(\"\"\"\n",
    "    SELECT \n",
    "        A.ROWKEY,\n",
    "        A.name AS old_name,\n",
    "        B.name AS changes_name\n",
    "    FROM demo_1_stream A\n",
    "        LEFT JOIN demo_2_stream B WITHIN 1 HOURS ON A.ROWKEY = B.ROWKEY\n",
    "    EMIT CHANGES\n",
    "\"\"\", stream_properties={\"ksql.streams.auto.offset.reset\": \"earliest\"})\n",
    "max_row = 4\n",
    "i = 0\n",
    "for item in q:\n",
    "    if i > max_row:\n",
    "        break \n",
    "    print(item)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done :)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcd6bd7c2b856ae1f1ae6f2caf69728be297e6a0b21596dbacb1a3f7a486f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
